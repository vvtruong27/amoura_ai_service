{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T02:22:03.417083Z",
     "start_time": "2025-06-07T02:22:02.992950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "from datetime import datetime"
   ],
   "id": "b79ea0ebc4c92756",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T02:22:03.431117Z",
     "start_time": "2025-06-07T02:22:03.422861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- START OF HELPER FUNCTIONS ---\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # Radius of Earth in kilometers\n",
    "\n",
    "    lat1_rad = radians(lat1)\n",
    "    lon1_rad = radians(lon1)\n",
    "    lat2_rad = radians(lat2)\n",
    "    lon2_rad = radians(lon2)\n",
    "\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "def calculate_age(born_str):\n",
    "    born = datetime.strptime(born_str, '%Y-%m-%d')\n",
    "    today = datetime.today()\n",
    "    return today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "\n",
    "def preprocess_features(df):\n",
    "    # Calculate Age\n",
    "    df['age'] = df['date_of_birth'].apply(calculate_age)\n",
    "\n",
    "    # Numerical features to scale\n",
    "    numerical_features = ['height', 'age']\n",
    "    scaler = StandardScaler() # or MinMaxScaler()\n",
    "    df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "    # Categorical features for one-hot encoding\n",
    "    # 'sex' and 'orientation' are handled separately for compatibility matrix\n",
    "    # but can also be included here for general similarity if desired.\n",
    "    categorical_features = ['body_type', 'job', 'drink', 'smoke', 'education_level']\n",
    "    df_categorical = pd.get_dummies(df[categorical_features], prefix=categorical_features, dummy_na=False) # Handle NaNs if any\n",
    "\n",
    "    # Binary features\n",
    "    binary_features = ['interested_in_new_language', 'dropped_out_school']\n",
    "    df_binary = df[binary_features].astype(int)\n",
    "\n",
    "    # Multi-hot encode list-like features\n",
    "    # Pets\n",
    "    df['pets_list'] = df['pets'].apply(lambda x: [p.strip() for p in x.split(' - ')] if pd.notna(x) and x else [])\n",
    "    mlb_pets = MultiLabelBinarizer()\n",
    "    df_pets = pd.DataFrame(mlb_pets.fit_transform(df['pets_list']), columns=['pet_' + c for c in mlb_pets.classes_], index=df.index)\n",
    "\n",
    "    # Interests\n",
    "    df['interests_list'] = df['interests'].apply(lambda x: [i.strip() for i in x.split(' - ')] if pd.notna(x) and x else [])\n",
    "    mlb_interests = MultiLabelBinarizer()\n",
    "    df_interests = pd.DataFrame(mlb_interests.fit_transform(df['interests_list']), columns=['interest_' + c for c in mlb_interests.classes_], index=df.index)\n",
    "\n",
    "    # Languages\n",
    "    df['languages_list'] = df['languages'].apply(lambda x: [l.strip() for l in x.split(' - ')] if pd.notna(x) and x else [])\n",
    "    # Using CountVectorizer for languages as it's more common for language proficiency features\n",
    "    # However, MultiLabelBinarizer is also fine for just knowing the language.\n",
    "    # Let's stick to MultiLabelBinarizer for consistency here.\n",
    "    mlb_languages = MultiLabelBinarizer()\n",
    "    df_languages = pd.DataFrame(mlb_languages.fit_transform(df['languages_list']), columns=['lang_' + c for c in mlb_languages.classes_], index=df.index)\n",
    "\n",
    "    # Combine all processed features\n",
    "    # We are not including lat/lon directly in cosine similarity for Matrix 1\n",
    "    # as distance will be part of Matrix 2 (compatibility filter).\n",
    "    # If you wanted to include location as a feature for similarity, you might\n",
    "    # consider transforming lat/lon (e.g. using sin/cos transforms) or\n",
    "    # using distance to a reference point, but it's often complex.\n",
    "    feature_df = pd.concat([df[numerical_features], df_categorical, df_binary, df_pets, df_interests, df_languages], axis=1)\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "# --- END OF HELPER FUNCTIONS ---"
   ],
   "id": "dff32a08b42667c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T02:22:03.554043Z",
     "start_time": "2025-06-07T02:22:03.520305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "csv_file_path = '../data/match_profiles.csv'\n",
    "df_users = pd.read_csv(csv_file_path)\n",
    "df_users.set_index('id', inplace=True) # Set 'id' as index"
   ],
   "id": "fc28763e5607eb83",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T02:22:03.663115Z",
     "start_time": "2025-06-07T02:22:03.567998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Matrix 1: User-User Similarity Matrix ---\n",
    "print(\"Preprocessing features for Matrix 1...\")\n",
    "feature_matrix = preprocess_features(df_users.copy()) # Use .copy() to avoid SettingWithCopyWarning on original df_users\n",
    "print(f\"Feature matrix shape: {feature_matrix.shape}\")\n",
    "\n",
    "print(\"Calculating cosine similarity (Matrix 1)...\")\n",
    "# Fill NaN values that might have occurred if a category was all NaN before one-hot encoding (unlikely with this data)\n",
    "# Or if scaler produced NaNs (also unlikely with StandardScaler on non-NaN data)\n",
    "feature_matrix_filled = feature_matrix.fillna(0)\n",
    "similarity_matrix_S = cosine_similarity(feature_matrix_filled)\n",
    "\n",
    "# Convert to DataFrame for easier handling with user IDs\n",
    "similarity_df = pd.DataFrame(similarity_matrix_S, index=df_users.index, columns=df_users.index)\n",
    "\n",
    "# Set diagonal elements to 0 (user cannot match with themselves)\n",
    "np.fill_diagonal(similarity_df.values, 0)\n",
    "print(\"Matrix 1 (Similarity Matrix) created.\")"
   ],
   "id": "dee7c6c86af9ff6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing features for Matrix 1...\n",
      "Feature matrix shape: (2001, 81)\n",
      "Calculating cosine similarity (Matrix 1)...\n",
      "Matrix 1 (Similarity Matrix) created.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T02:29:26.436629Z",
     "start_time": "2025-06-07T02:22:03.716293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Matrix 2: Binary User-User Compatibility Matrix ---\n",
    "print(\"Creating Compatibility Matrix (Matrix 2)...\")\n",
    "num_users = len(df_users)\n",
    "compatibility_matrix = pd.DataFrame(np.zeros((num_users, num_users)), index=df_users.index, columns=df_users.index)\n",
    "\n",
    "# Pre-calculate all pairwise distances\n",
    "print(\"Calculating pairwise distances...\")\n",
    "distances = np.zeros((num_users, num_users))\n",
    "user_ids_list = df_users.index.tolist()\n",
    "lat_lon_map = df_users[['latitude', 'longitude']].to_dict('index')\n",
    "\n",
    "for i in range(num_users):\n",
    "    for j in range(i + 1, num_users):\n",
    "        user1_id = user_ids_list[i]\n",
    "        user2_id = user_ids_list[j]\n",
    "\n",
    "        lat1, lon1 = lat_lon_map[user1_id]['latitude'], lat_lon_map[user1_id]['longitude']\n",
    "        lat2, lon2 = lat_lon_map[user2_id]['latitude'], lat_lon_map[user2_id]['longitude']\n",
    "\n",
    "        dist = haversine(lat1, lon1, lat2, lon2)\n",
    "        distances[i, j] = dist\n",
    "        distances[j, i] = dist\n",
    "\n",
    "distance_df = pd.DataFrame(distances, index=df_users.index, columns=df_users.index)\n",
    "print(\"Pairwise distances calculated.\")\n",
    "\n",
    "for i_idx, user1_id in enumerate(df_users.index):\n",
    "    for j_idx, user2_id in enumerate(df_users.index):\n",
    "        if user1_id == user2_id:\n",
    "            compatibility_matrix.loc[user1_id, user2_id] = 0\n",
    "            continue\n",
    "\n",
    "        user1 = df_users.loc[user1_id]\n",
    "        user2 = df_users.loc[user2_id]\n",
    "\n",
    "        # 1. Orientation Compatibility\n",
    "        compatible_orientation = False\n",
    "        s1, o1 = user1['sex'], user1['orientation']\n",
    "        s2, o2 = user2['sex'], user2['orientation']\n",
    "\n",
    "        # Define who user1 is interested in based on their orientation\n",
    "        user1_interested_in_user2 = False\n",
    "        if o1 == 'straight':\n",
    "            if (s1 == 'male' and s2 == 'female') or \\\n",
    "               (s1 == 'female' and s2 == 'male'):\n",
    "                user1_interested_in_user2 = True\n",
    "            # non-binary straight could be interested in other non-binary, or specific gender\n",
    "            elif s1 == 'non-binary' and s2 != 'non-binary': # Simplified: straight non-binary interested in male/female\n",
    "                 user1_interested_in_user2 = True\n",
    "        elif o1 == 'homosexual':\n",
    "            if s1 == s2 : # Covers male-male, female-female, non-binary-non-binary\n",
    "                user1_interested_in_user2 = True\n",
    "        elif o1 == 'bisexual':\n",
    "            user1_interested_in_user2 = True # Assumes bisexual can be interested in any listed sex\n",
    "\n",
    "        # Define who user2 is interested in based on their orientation\n",
    "        user2_interested_in_user1 = False\n",
    "        if o2 == 'straight':\n",
    "            if (s2 == 'male' and s1 == 'female') or \\\n",
    "               (s2 == 'female' and s1 == 'male'):\n",
    "                user2_interested_in_user1 = True\n",
    "            elif s2 == 'non-binary' and s1 != 'non-binary':\n",
    "                 user2_interested_in_user1 = True\n",
    "        elif o2 == 'homosexual':\n",
    "            if s2 == s1:\n",
    "                user2_interested_in_user1 = True\n",
    "        elif o2 == 'bisexual':\n",
    "            user2_interested_in_user1 = True\n",
    "\n",
    "        if user1['sex'] == 'prefer not to say' or user2['sex'] == 'prefer not to say' or \\\n",
    "           user1['orientation'] == 'prefer not to say' or user2['orientation'] == 'prefer not to say':\n",
    "            # If either has 'prefer not to say' for sex or orientation,\n",
    "            # they are only compatible if both are bisexual or both 'prefer not to say' orientation\n",
    "            # This is a simplification; complex rules could be added\n",
    "            if (user1['orientation'] == 'bisexual' or user1['orientation'] == 'prefer not to say') and \\\n",
    "               (user2['orientation'] == 'bisexual' or user2['orientation'] == 'prefer not to say'):\n",
    "                 compatible_orientation = True # Let similarity decide more\n",
    "            else:\n",
    "                compatible_orientation = False\n",
    "        elif user1_interested_in_user2 and user2_interested_in_user1:\n",
    "            compatible_orientation = True\n",
    "\n",
    "        if not compatible_orientation:\n",
    "            compatibility_matrix.loc[user1_id, user2_id] = 0\n",
    "            continue\n",
    "\n",
    "        # 2. Location Compatibility\n",
    "        dist = distance_df.loc[user1_id, user2_id]\n",
    "\n",
    "        pref1 = user1['location_preference']\n",
    "        pref2 = user2['location_preference']\n",
    "\n",
    "        compatible_location1 = (pref1 == -1) or (dist <= pref1)\n",
    "        compatible_location2 = (pref2 == -1) or (dist <= pref2)\n",
    "\n",
    "        if compatible_location1 and compatible_location2:\n",
    "            compatibility_matrix.loc[user1_id, user2_id] = 1\n",
    "        else:\n",
    "            compatibility_matrix.loc[user1_id, user2_id] = 0\n",
    "\n",
    "print(\"Matrix 2 (Compatibility Matrix) created.\")"
   ],
   "id": "9bb0f1b864952b2a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Compatibility Matrix (Matrix 2)...\n",
      "Calculating pairwise distances...\n",
      "Pairwise distances calculated.\n",
      "Matrix 2 (Compatibility Matrix) created.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T02:29:26.810962Z",
     "start_time": "2025-06-07T02:29:26.579054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Final Match Percentage Matrix ---\n",
    "print(\"Calculating final match percentage matrix...\")\n",
    "# Cosine similarity outputs values between -1 and 1.\n",
    "# For non-negative feature vectors (after one-hot encoding etc.), it's usually 0 to 1.\n",
    "# We can scale it to 0-100 if desired, or keep as 0-1.\n",
    "# Let's ensure similarity_df is non-negative for match percentage.\n",
    "# Since we scaled features with StandardScaler, some could be negative.\n",
    "# MinMaxScaler on feature_matrix would ensure 0-1 range for cosine similarity.\n",
    "# Alternatively, we can shift and scale the similarity_df: (similarity_df + 1) / 2 to map [-1,1] to [0,1]\n",
    "# Or simply clip negative values if they are very small and due to numerical precision\n",
    "# For this problem, given the diverse features, some negative cosine similarities are possible.\n",
    "# Let's rescale similarity_df to be [0, 1] for interpretability as a \"score\" before combining.\n",
    "min_sim = similarity_df.min().min()\n",
    "max_sim = similarity_df.max().max()\n",
    "if min_sim < 0 or max_sim > 1 : # Rescale if not already in approx [0,1] (after diagonal is zeroed)\n",
    "    # If min_sim is very close to 0 (e.g. -1e-9), clipping might be enough\n",
    "    # For a general case, rescaling:\n",
    "    similarity_df_scaled = (similarity_df - min_sim) / (max_sim - min_sim)\n",
    "    # Ensure diagonal is still 0 after scaling\n",
    "    np.fill_diagonal(similarity_df_scaled.values, 0)\n",
    "else:\n",
    "    similarity_df_scaled = similarity_df.clip(lower=0) # Clip any small negative values\n",
    "\n",
    "final_match_matrix = similarity_df_scaled * compatibility_matrix\n",
    "# To represent as percentage:\n",
    "final_match_matrix_percentage = final_match_matrix * 100\n",
    "\n",
    "print(\"Final Match Percentage Matrix calculated.\")\n",
    "print(\"\\nSample of the Final Match Percentage Matrix (Top 5x5):\")\n",
    "print(final_match_matrix_percentage.iloc[:5, :5])\n",
    "\n",
    "print(\"\\nExample: Match percentages for user 1 with users 2 to 5:\")\n",
    "print(final_match_matrix_percentage.loc[1, 2:6])\n",
    "\n",
    "# You can save this matrix to a CSV if needed\n",
    "# final_match_matrix_percentage.to_csv('final_user_match_percentages.csv')\n",
    "print(\"\\nDone.\")# --- Final Match Percentage Matrix ---\n",
    "print(\"Calculating final match percentage matrix...\")\n",
    "# Cosine similarity outputs values between -1 and 1.\n",
    "# For non-negative feature vectors (after one-hot encoding etc.), it's usually 0 to 1.\n",
    "# We can scale it to 0-100 if desired, or keep as 0-1.\n",
    "# Let's ensure similarity_df is non-negative for match percentage.\n",
    "# Since we scaled features with StandardScaler, some could be negative.\n",
    "# MinMaxScaler on feature_matrix would ensure 0-1 range for cosine similarity.\n",
    "# Alternatively, we can shift and scale the similarity_df: (similarity_df + 1) / 2 to map [-1,1] to [0,1]\n",
    "# Or simply clip negative values if they are very small and due to numerical precision\n",
    "# For this problem, given the diverse features, some negative cosine similarities are possible.\n",
    "# Let's rescale similarity_df to be [0, 1] for interpretability as a \"score\" before combining.\n",
    "min_sim = similarity_df.min().min()\n",
    "max_sim = similarity_df.max().max()\n",
    "if min_sim < 0 or max_sim > 1 : # Rescale if not already in approx [0,1] (after diagonal is zeroed)\n",
    "    # If min_sim is very close to 0 (e.g. -1e-9), clipping might be enough\n",
    "    # For a general case, rescaling:\n",
    "    similarity_df_scaled = (similarity_df - min_sim) / (max_sim - min_sim)\n",
    "    # Ensure diagonal is still 0 after scaling\n",
    "    np.fill_diagonal(similarity_df_scaled.values, 0)\n",
    "else:\n",
    "    similarity_df_scaled = similarity_df.clip(lower=0) # Clip any small negative values\n",
    "\n",
    "final_match_matrix = similarity_df_scaled * compatibility_matrix\n",
    "# To represent as percentage:\n",
    "final_match_matrix_percentage = final_match_matrix * 100\n",
    "\n",
    "print(\"Final Match Percentage Matrix calculated.\")\n",
    "print(\"\\nSample of the Final Match Percentage Matrix (Top 5x5):\")\n",
    "print(final_match_matrix_percentage.iloc[:5, :5])\n",
    "\n",
    "print(\"\\nExample: Match percentages for user 1 with users 2 to 5:\")\n",
    "print(final_match_matrix_percentage.loc[1, 2:6])\n",
    "\n",
    "# You can save this matrix to a CSV if needed\n",
    "# final_match_matrix_percentage.to_csv('../data/match_percentages.csv')\n",
    "print(\"\\nDone.\")"
   ],
   "id": "749f04de873660cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating final match percentage matrix...\n",
      "Final Match Percentage Matrix calculated.\n",
      "\n",
      "Sample of the Final Match Percentage Matrix (Top 5x5):\n",
      "id          1    2          3          4          5\n",
      "id                                                 \n",
      "1    0.000000  0.0  71.647858   0.000000  55.956462\n",
      "2    0.000000  0.0   0.000000   0.000000   0.000000\n",
      "3   71.647858  0.0   0.000000   0.000000  61.902894\n",
      "4    0.000000  0.0   0.000000   0.000000  58.004206\n",
      "5   55.956462  0.0  61.902894  58.004206   0.000000\n",
      "\n",
      "Example: Match percentages for user 1 with users 2 to 5:\n",
      "id\n",
      "2     0.000000\n",
      "3    71.647858\n",
      "4     0.000000\n",
      "5    55.956462\n",
      "6     0.000000\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "Done.\n",
      "Calculating final match percentage matrix...\n",
      "Final Match Percentage Matrix calculated.\n",
      "\n",
      "Sample of the Final Match Percentage Matrix (Top 5x5):\n",
      "id          1    2          3          4          5\n",
      "id                                                 \n",
      "1    0.000000  0.0  71.647858   0.000000  55.956462\n",
      "2    0.000000  0.0   0.000000   0.000000   0.000000\n",
      "3   71.647858  0.0   0.000000   0.000000  61.902894\n",
      "4    0.000000  0.0   0.000000   0.000000  58.004206\n",
      "5   55.956462  0.0  61.902894  58.004206   0.000000\n",
      "\n",
      "Example: Match percentages for user 1 with users 2 to 5:\n",
      "id\n",
      "2     0.000000\n",
      "3    71.647858\n",
      "4     0.000000\n",
      "5    55.956462\n",
      "6     0.000000\n",
      "Name: 1, dtype: float64\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T02:29:27.075234Z",
     "start_time": "2025-06-07T02:29:27.014130Z"
    }
   },
   "cell_type": "code",
   "source": "final_match_matrix_percentage",
   "id": "165495a9b7253163",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         1     2          3          4          5          6          7     \\\n",
       "id                                                                             \n",
       "1      0.000000   0.0  71.647858   0.000000  55.956462   0.000000  47.555614   \n",
       "2      0.000000   0.0   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3     71.647858   0.0   0.000000   0.000000  61.902894   0.000000   0.000000   \n",
       "4      0.000000   0.0   0.000000   0.000000  58.004206   0.000000   0.000000   \n",
       "5     55.956462   0.0  61.902894  58.004206   0.000000  62.232434  53.272082   \n",
       "...         ...   ...        ...        ...        ...        ...        ...   \n",
       "1997   0.000000   0.0  70.979704   0.000000  63.036185   0.000000   0.000000   \n",
       "1998  70.936857   0.0   0.000000   0.000000  59.838410   0.000000  42.855875   \n",
       "1999   0.000000   0.0  66.733999   0.000000  58.750353   0.000000   0.000000   \n",
       "2000   0.000000   0.0   0.000000   0.000000  49.471048   0.000000   0.000000   \n",
       "2001   0.000000   0.0   0.000000  67.130088   0.000000  57.163903   0.000000   \n",
       "\n",
       "id         8          9          10    ...       1992       1993       1994  \\\n",
       "id                                     ...                                    \n",
       "1      0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000   \n",
       "2      0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000   \n",
       "3      0.000000   0.000000  49.758115  ...   0.000000   0.000000   0.000000   \n",
       "4      0.000000  61.799168   0.000000  ...  62.870167   0.000000  64.854645   \n",
       "5     41.910694   0.000000  58.136731  ...   0.000000  43.138222   0.000000   \n",
       "...         ...        ...        ...  ...        ...        ...        ...   \n",
       "1997   0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000   \n",
       "1998   0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000   \n",
       "1999   0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000   \n",
       "2000   0.000000   0.000000   0.000000  ...   0.000000   0.000000   0.000000   \n",
       "2001   0.000000   0.000000   0.000000  ...   0.000000  50.809366   0.000000   \n",
       "\n",
       "id         1995       1996       1997       1998       1999       2000  \\\n",
       "id                                                                       \n",
       "1      0.000000   0.000000   0.000000  70.936857   0.000000   0.000000   \n",
       "2      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3      0.000000   0.000000  70.979704   0.000000  66.733999   0.000000   \n",
       "4     56.149929   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "5      0.000000  46.489551  63.036185  59.838410  58.750353  49.471048   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1997   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1998   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1999   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2000   0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2001   0.000000  60.079575   0.000000   0.000000   0.000000  64.333244   \n",
       "\n",
       "id         2001  \n",
       "id               \n",
       "1      0.000000  \n",
       "2      0.000000  \n",
       "3      0.000000  \n",
       "4     67.130088  \n",
       "5      0.000000  \n",
       "...         ...  \n",
       "1997   0.000000  \n",
       "1998   0.000000  \n",
       "1999   0.000000  \n",
       "2000  64.333244  \n",
       "2001   0.000000  \n",
       "\n",
       "[2001 rows x 2001 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.647858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.956462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.555614</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.936857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.647858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.902894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.758115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.979704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>66.733999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.004206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>61.799168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>62.870167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.854645</td>\n",
       "      <td>56.149929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.130088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.956462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.902894</td>\n",
       "      <td>58.004206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62.232434</td>\n",
       "      <td>53.272082</td>\n",
       "      <td>41.910694</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.136731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.138222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.489551</td>\n",
       "      <td>63.036185</td>\n",
       "      <td>59.838410</td>\n",
       "      <td>58.750353</td>\n",
       "      <td>49.471048</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.979704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.036185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>70.936857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.838410</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.855875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.733999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.750353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.471048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.333244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.130088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.163903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.809366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.079575</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>64.333244</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2001 rows × 2001 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T02:29:57.498856Z",
     "start_time": "2025-06-07T02:29:27.698282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# GIẢ SỬ BẠN ĐÃ CÓ final_match_matrix_percentage TỪ BƯỚC TRƯỚC\n",
    "# Ví dụ tạo một ma trận giả lập nếu bạn chưa chạy bước trước:\n",
    "# Đây là ma trận TỶ LỆ % (0-100)\n",
    "# user_ids = list(range(1, 101)) # Ví dụ với 100 users\n",
    "# num_users = len(user_ids)\n",
    "# # Tạo ma trận ngẫu nhiên, sau đó làm đối xứng và đặt đường chéo bằng 0\n",
    "# final_match_matrix_percentage_data = np.random.rand(num_users, num_users) * 100\n",
    "# final_match_matrix_percentage_data = (final_match_matrix_percentage_data + final_match_matrix_percentage_data.T) / 2\n",
    "# np.fill_diagonal(final_match_matrix_percentage_data, 0)\n",
    "# # Giả sử chỉ một phần nhỏ có match > 0 để mô phỏng thực tế\n",
    "# for i in range(num_users):\n",
    "#     for j in range(i + 1, num_users):\n",
    "#         if random.random() > 0.8: # ~20% có thể có match\n",
    "#             pass\n",
    "#         else:\n",
    "#             final_match_matrix_percentage_data[i, j] = 0\n",
    "#             final_match_matrix_percentage_data[j, i] = 0\n",
    "# final_match_matrix_percentage = pd.DataFrame(final_match_matrix_percentage_data, index=user_ids, columns=user_ids)\n",
    "# print(\"Ma trận ví dụ final_match_matrix_percentage (5x5 đầu):\")\n",
    "# print(final_match_matrix_percentage.iloc[:5,:5])\n",
    "# print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- BẮT ĐẦU TẠO CẶP MATCH NGẪU NHIÊN ---\n",
    "\n",
    "\n",
    "\n",
    "all_user_ids = final_match_matrix_percentage.index.tolist()\n",
    "min_matches_per_user = 1\n",
    "max_matches_per_user = 25\n",
    "\n",
    "# Lưu trữ các cặp đã chọn để tránh trùng lặp (user_id_1, user_id_2) với user_id_1 < user_id_2\n",
    "selected_pairs_set = set()\n",
    "# Lưu trữ kết quả cuối cùng\n",
    "final_selected_matches = []\n",
    "# Theo dõi số lượng match hiện tại của mỗi user\n",
    "user_actual_match_counts = defaultdict(int)\n",
    "\n",
    "print(\"Bắt đầu quá trình chọn cặp match...\")\n",
    "\n",
    "# Giai đoạn 1: Ưu tiên chọn cho mỗi user để đạt số lượng match mong muốn (random trong khoảng min-max)\n",
    "# Xáo trộn danh sách user để thứ tự xử lý không ảnh hưởng quá nhiều\n",
    "random.shuffle(all_user_ids)\n",
    "\n",
    "for user1_id in all_user_ids:\n",
    "    if user_actual_match_counts[user1_id] >= max_matches_per_user:\n",
    "        continue\n",
    "\n",
    "    potential_partners = []\n",
    "    for user2_id in all_user_ids:\n",
    "        if user1_id == user2_id:\n",
    "            continue\n",
    "\n",
    "        match_score = final_match_matrix_percentage.loc[user1_id, user2_id]\n",
    "        if match_score > 0:\n",
    "            # Chỉ xem xét user2 nếu họ chưa đạt max_matches\n",
    "            if user_actual_match_counts[user2_id] < max_matches_per_user:\n",
    "                # Đảm bảo cặp chưa được thêm vào\n",
    "                pair_key = tuple(sorted((user1_id, user2_id)))\n",
    "                if pair_key not in selected_pairs_set:\n",
    "                    potential_partners.append({'partner_id': user2_id, 'score': match_score})\n",
    "\n",
    "    random.shuffle(potential_partners) # Xáo trộn các đối tác tiềm năng\n",
    "\n",
    "    # Xác định số lượng match mục tiêu cho user1_id này\n",
    "    # User này cần ít nhất là min_matches_per_user, hoặc nhiều hơn nếu có thể, tối đa là max_matches_per_user\n",
    "\n",
    "    # Số lượng match mà user1_id còn thiếu để đạt min\n",
    "    needed_for_min = max(0, min_matches_per_user - user_actual_match_counts[user1_id])\n",
    "    # Số lượng match user1_id có thể thêm mà không vượt max\n",
    "    can_add_up_to_max = max_matches_per_user - user_actual_match_counts[user1_id]\n",
    "\n",
    "    # Nếu user1_id chưa đủ min_matches, cố gắng đạt min_matches\n",
    "    # Nếu đã đủ, thì chọn thêm ngẫu nhiên để đạt một con số trong khoảng [current_count, max_matches_per_user]\n",
    "    # hoặc đơn giản là chọn một target_n_matches ngẫu nhiên trong [min_overall, max_overall]\n",
    "\n",
    "    # Số lượng match mong muốn cho user này, nằm trong khoảng [min_matches_per_user, max_matches_per_user]\n",
    "    # nhưng cũng bị giới hạn bởi số potential_partners thực tế và số slot còn trống của user1_id\n",
    "\n",
    "    # Số match mục tiêu tổng cộng cho user1\n",
    "    target_n_matches_for_user1 = random.randint(\n",
    "        min(min_matches_per_user, len(potential_partners) + user_actual_match_counts[user1_id]), # đảm bảo nếu ít potential thì ko cố random quá cao\n",
    "        min(max_matches_per_user, len(potential_partners) + user_actual_match_counts[user1_id])\n",
    "    )\n",
    "\n",
    "    # Số match cần chọn thêm cho user1\n",
    "    num_to_select_now = max(0, target_n_matches_for_user1 - user_actual_match_counts[user1_id])\n",
    "\n",
    "\n",
    "    added_this_iteration = 0\n",
    "    for partner_info in potential_partners:\n",
    "        if added_this_iteration >= num_to_select_now:\n",
    "            break\n",
    "        if user_actual_match_counts[user1_id] >= max_matches_per_user: # Re-check user1\n",
    "            break\n",
    "\n",
    "        user2_id = partner_info['partner_id']\n",
    "        score = partner_info['score']\n",
    "\n",
    "        # Kiểm tra lại user2_id vì count của nó có thể đã thay đổi do các user khác chọn\n",
    "        if user_actual_match_counts[user2_id] < max_matches_per_user:\n",
    "            pair_key = tuple(sorted((user1_id, user2_id)))\n",
    "            if pair_key not in selected_pairs_set:\n",
    "                final_selected_matches.append({\n",
    "                    'user_id_1': pair_key[0],\n",
    "                    'user_id_2': pair_key[1],\n",
    "                    'match_percent': score\n",
    "                })\n",
    "                selected_pairs_set.add(pair_key)\n",
    "                user_actual_match_counts[user1_id] += 1\n",
    "                user_actual_match_counts[user2_id] += 1\n",
    "                added_this_iteration += 1\n",
    "\n",
    "# Giai đoạn 2: Kiểm tra và bổ sung cho những user chưa đủ min_matches_per_user\n",
    "print(\"Giai đoạn 2: Đảm bảo số match tối thiểu...\")\n",
    "for user1_id in all_user_ids:\n",
    "    if user_actual_match_counts[user1_id] < min_matches_per_user and \\\n",
    "       user_actual_match_counts[user1_id] < max_matches_per_user: # user này chưa đủ min và chưa đạt max\n",
    "\n",
    "        needed_more = min_matches_per_user - user_actual_match_counts[user1_id]\n",
    "\n",
    "        potential_partners_fill = []\n",
    "        for user2_id in all_user_ids:\n",
    "            if user1_id == user2_id:\n",
    "                continue\n",
    "            match_score = final_match_matrix_percentage.loc[user1_id, user2_id]\n",
    "            if match_score > 0:\n",
    "                pair_key = tuple(sorted((user1_id, user2_id)))\n",
    "                if pair_key not in selected_pairs_set and \\\n",
    "                   user_actual_match_counts[user2_id] < max_matches_per_user: # user2 cũng chưa đạt max\n",
    "                    potential_partners_fill.append({'partner_id': user2_id, 'score': match_score})\n",
    "\n",
    "        random.shuffle(potential_partners_fill)\n",
    "\n",
    "        added_in_fill_phase = 0\n",
    "        for partner_info in potential_partners_fill:\n",
    "            if added_in_fill_phase >= needed_more:\n",
    "                break\n",
    "            if user_actual_match_counts[user1_id] >= max_matches_per_user: # Re-check user1\n",
    "                 break\n",
    "\n",
    "            user2_id = partner_info['partner_id']\n",
    "            score = partner_info['score']\n",
    "\n",
    "            if user_actual_match_counts[user2_id] < max_matches_per_user: # Re-check user2\n",
    "                pair_key = tuple(sorted((user1_id, user2_id)))\n",
    "                # Mặc dù đã check selected_pairs_set ở trên, check lại cho chắc\n",
    "                if pair_key not in selected_pairs_set:\n",
    "                    final_selected_matches.append({\n",
    "                        'user_id_1': pair_key[0],\n",
    "                        'user_id_2': pair_key[1],\n",
    "                        'match_percent': score\n",
    "                    })\n",
    "                    selected_pairs_set.add(pair_key)\n",
    "                    user_actual_match_counts[user1_id] += 1\n",
    "                    user_actual_match_counts[user2_id] += 1\n",
    "                    added_in_fill_phase += 1\n",
    "\n",
    "\n",
    "# Chuyển đổi danh sách kết quả thành DataFrame\n",
    "output_df = pd.DataFrame(final_selected_matches)\n",
    "\n",
    "# Sắp xếp lại để user_id_1 luôn nhỏ hơn user_id_2 (mặc dù đã cố gắng làm ở trên)\n",
    "# Điều này không cần thiết nếu pair_key đã được dùng đúng cách\n",
    "#mask = output_df['user_id_1'] > output_df['user_id_2']\n",
    "#output_df.loc[mask, ['user_id_1', 'user_id_2']] = output_df.loc[mask, ['user_id_2', 'user_id_1']].values\n",
    "#output_df = output_df.drop_duplicates(subset=['user_id_1', 'user_id_2'])\n",
    "\n",
    "\n",
    "print(f\"\\nTổng số cặp match được tạo: {len(output_df)}\")\n",
    "\n",
    "# Kiểm tra số lượng match cho mỗi user\n",
    "print(\"\\nKiểm tra số lượng match cho mỗi user (Top 10 users):\")\n",
    "final_counts_check = defaultdict(int)\n",
    "for _, row in output_df.iterrows():\n",
    "    final_counts_check[row['user_id_1']] += 1\n",
    "    final_counts_check[row['user_id_2']] += 1\n",
    "\n",
    "# for i, user_id in enumerate(all_user_ids):\n",
    "#     if i < 10:\n",
    "#         print(f\"User {user_id}: {final_counts_check[user_id]} matches\")\n",
    "#     if final_counts_check[user_id] < min_matches_per_user:\n",
    "#         print(f\"!!! CẢNH BÁO: User {user_id} có {final_counts_check[user_id]} matches (ít hơn {min_matches_per_user})\")\n",
    "#     if final_counts_check[user_id] > max_matches_per_user:\n",
    "#         print(f\"!!! CẢNH BÁO: User {user_id} có {final_counts_check[user_id]} matches (nhiều hơn {max_matches_per_user})\")\n",
    "\n",
    "\n",
    "# Phân tích số lượng match\n",
    "counts_series = pd.Series(final_counts_check)\n",
    "print(\"\\nThống kê số lượng match mỗi user:\")\n",
    "print(counts_series.describe())\n",
    "print(f\"Số user có ít hơn {min_matches_per_user} match: {(counts_series < min_matches_per_user).sum()} (trong số {len(all_user_ids)} users)\")\n",
    "print(f\"Số user có nhiều hơn {max_matches_per_user} match: {(counts_series > max_matches_per_user).sum()}\")\n",
    "users_less_than_min = counts_series[counts_series < min_matches_per_user].index.tolist()\n",
    "if users_less_than_min:\n",
    "    print(f\"Các user có ít hơn {min_matches_per_user} match: {users_less_than_min[:20]}...\") # In ra 20 user đầu tiên\n",
    "\n",
    "\n",
    "# Hiển thị một vài dòng của kết quả\n",
    "print(\"\\nMột vài cặp match ngẫu nhiên đã tạo:\")\n",
    "print(output_df.head(10))"
   ],
   "id": "e73a4c8ab0cb5d6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bắt đầu quá trình chọn cặp match...\n",
      "Giai đoạn 2: Đảm bảo số match tối thiểu...\n",
      "\n",
      "Tổng số cặp match được tạo: 16586\n",
      "\n",
      "Kiểm tra số lượng match cho mỗi user (Top 10 users):\n",
      "\n",
      "Thống kê số lượng match mỗi user:\n",
      "count    1962.000000\n",
      "mean       16.907238\n",
      "std         6.889198\n",
      "min         1.000000\n",
      "25%        11.000000\n",
      "50%        18.000000\n",
      "75%        24.000000\n",
      "max        25.000000\n",
      "dtype: float64\n",
      "Số user có ít hơn 1 match: 0 (trong số 2001 users)\n",
      "Số user có nhiều hơn 25 match: 0\n",
      "\n",
      "Một vài cặp match ngẫu nhiên đã tạo:\n",
      "   user_id_1  user_id_2  match_percent\n",
      "0         69       1860      46.451159\n",
      "1       1251       1860      52.599438\n",
      "2         97       1860      50.887971\n",
      "3        509       1860      50.037166\n",
      "4       1280       1860      48.700275\n",
      "5       1591       1860      52.168964\n",
      "6        324       1860      52.607573\n",
      "7       1505       1860      52.081170\n",
      "8        203       1860      62.879201\n",
      "9       1860       1919      56.115403\n",
      "\n",
      "Đã lưu kết quả vào file: ../data/matched_pairs.csv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T03:12:11.705474Z",
     "start_time": "2025-06-07T03:12:11.542715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lưu vào file CSV\n",
    "output_df.drop(columns=[\"match_percent\"], inplace=True)\n",
    "output_filename = '../data/matched_pairs.csv'\n",
    "output_df.to_csv(output_filename, index=False)\n",
    "print(f\"\\nĐã lưu kết quả vào file: {output_filename}\")"
   ],
   "id": "2063cf1faad745f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Đã lưu kết quả vào file: ../data/matched_pairs.csv\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
